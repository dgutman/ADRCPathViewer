{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import os,csv,sys\n",
    "import openslide\n",
    "import dsa_mongo_common_functions as dsa\n",
    "import cdsa_loader_helper_functions as cdsa_helpers\n",
    "import pprint\n",
    "from os.path import join as oj\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "dsa_load_errors_db = client['DSA_LoadErrors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Potential Patient directories were identified\n",
      "['GBM', 'LGG', 'LUAD', 'SARC', 'SKCM']\n"
     ]
    }
   ],
   "source": [
    "dsa_slide_db = client['PanCanDSA_Slide_Data']  ### These need to be configured for the specific project\n",
    "## This is specific to a given fle system and or structurme\n",
    "slide_root = '/bigdata/PanCan_Images/'  ##Base Path for Slides\n",
    "feature_file_root = '/bigdata/PanCan_FeatureData/'\n",
    "\n",
    "feature_db = client['PanCan_BoundsOnly_V2'] ### Im going to make one for each cancer type..\n",
    "\n",
    "### To generalize this, need to describe organization, most common will be  PATIENT/STAIN_TYPE as subdirectories\n",
    "TLD_Dirs = [x for x in os.listdir(slide_root) if os.path.isdir(oj(slide_root,x))]\n",
    "print len(TLD_Dirs),\"Potential Patient directories were identified\"\n",
    "print subj_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_rawslide_lists( slide_root_path ):\n",
    "        \"\"\"project_name is passed along with the potentially more than one root image path for ndpi files\"\"\"\n",
    "        slide_files = []\n",
    "\n",
    "        slide_root_path  = slide_root_path.rstrip('/')\n",
    "        print slide_root_path\n",
    "        for dpath, dnames, fnames in os.walk( slide_root_path, followlinks=True):\n",
    "                \n",
    "                for file in fnames:\n",
    "                    if '.ndpi' in file or '.svs' in file:\n",
    "                                slide_files.append(dpath +'/'+file)\n",
    "        print len(slide_files),\"SVS or NDPI files were located\"\n",
    "        return slide_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print subj_dir_list\n",
    "print dsa_slide_db['RawSlideData'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### So this creates a document WITHIN the current database to store raw information about the slides\n",
    "## Now that I think about this, I really should not store the filename but the File Hash as I.. want to change the filenames\n",
    "\n",
    "for sd in subj_dir_list:\n",
    "    print sd,\"is being processed\",\n",
    "    curr_svs_slide_list = find_rawslide_lists(  os.path.join(slide_root,sd)  )\n",
    "    slides_processed = newly_processed = dup_slide = rescanned_slides =  0\n",
    "    for sld in curr_svs_slide_list:\n",
    "\n",
    "        slide_name = os.path.basename(sld)\n",
    "        qry = dsa_slide_db['RawSlideData'].find_one( {'slide_name':slide_name})\n",
    "        #print qry\n",
    "        if not qry:\n",
    "            fs = os.path.getsize(sld)\n",
    "            #md5Checksum = dsa.md5sum(sld)\n",
    "            (openslide_could_open, width, height, filesize, orig_resolution, slide_name,md5, sld_properties) = cdsa_helpers.openslide_test_file_mongo( sld, 'ndpi', client)\n",
    "            if openslide_could_open:\n",
    "                prep_type = 'Unknown'\n",
    "                slide_metadata = { 'slide_w_path': sld, 'slide_name': slide_name, 'file_size':fs, 'width':width, 'height':height,\n",
    "                                 'orig_resolution': orig_resolution, 'sld_properties': cdsa_helpers.clean_openslide_keys ( sld_properties), 'slide_md5': md5, 'prep_type': prep_type\n",
    "                                 }\n",
    "                dsa_slide_db['RawSlideData'].insert_one(slide_metadata)\n",
    "                newly_processed +=1 \n",
    "            else:\n",
    "                print \"UNABLE TO OPEN FILE??\",sld\n",
    "                ###Need to flag/load this in to an error database\n",
    "\n",
    "        else:\n",
    "            fs = os.path.getsize(sld)\n",
    "            ## Double check if file size matches\n",
    "#             if qry['file_size'] != fs:\n",
    "#                 #print \"File size mismatch??\",fs,qry['file_size'],qry['slide_w_path'],sld\n",
    "#                 load_errors_db['rescanned_slides'].insert_one( {'loaded_slide': qry['slide_w_path'], 'rescanned_slide': sld}             )\n",
    "#                 rescanned_slides +=1 \n",
    "#             else:\n",
    "#                 dup_slide +=1\n",
    "\n",
    "    \n",
    "        slides_processed +=1        \n",
    "        output = \"Total Processed: %d  Newly Processed: %d Dup Slides or Already Loaded: %d  RESCANNED Slides %d\" % (slides_processed, newly_processed, dup_slide, rescanned_slides )\n",
    "        dsa.LinePrinter(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFeatureInfo( slide_name, group_name):\n",
    "    \"\"\"Queries the feature Database and determine if there are any segmentations loaded\"\"\"\n",
    "    print \"received %s and %s\" % ( slide_name, group_name)\n",
    "# print dsa_slide_db['RawSlideData'].count()\n",
    "# dsa_slide_db['RawSlideData'].delete_many({})\n",
    "# print dsa_slide_db['RawSlideData'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features.V1.SARC.TCGA-DX-A6Z2-01A-01-TSA\n"
     ]
    }
   ],
   "source": [
    "all_feature_colls = feature_db.collection_names()\n",
    "print all_feature_colls[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### I now want to reformat all of this data to make it more useful for DSA ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_slides = dsa_slide_db['RawSlideData'].find()\n",
    "\n",
    "## Since this is pretty easy to recreate, I'm going to empty the current database\n",
    "\n",
    "dsa_slide_db['PanCanDSA_Slide_Data'].delete_many({})\n",
    "\n",
    "\n",
    "all_feature_colls = feature_db.collection_names()\n",
    "\n",
    "for s in all_slides:\n",
    "    slide_dict = {}\n",
    "    #pt_id = s['slide_w_path'].split('/')[-1]\n",
    "    slideGroup = s['slide_w_path'].split('/')[-2]\n",
    "    pt_id = s['slide_w_path'].split('/')[-1].split('.')[0]\n",
    "   # stain_type = s['slide_w_path'].split('/')[-2]\n",
    "    stain_type = 'UNK'\n",
    "    slide_dict = s.copy()\n",
    "    slide_dict.pop('_id',None)\n",
    "    \n",
    "    slide_dict['pt_id'] = pt_id\n",
    "    slide_dict['stain_type'] = stain_type\n",
    "    ### Obfuscating the global file path so everything is relative to some base path for the archive/\n",
    "    slide_dict['thumbnail_image'] = '/thumbnail/' + s['slide_w_path'].replace(slide_root,'')\n",
    "    slide_dict['slide_w_path'] = '/DZIMS/' + s['slide_w_path'].replace(slide_root,'')+'.dzi'\n",
    "#    slide_dict['slide_w_path'] = '/DZIMS' + s['slide_w_path']+'.dzi'\n",
    "    slide_dict['slideGroup'] = slideGroup\n",
    "    \n",
    "    slide_dict['HasPathReport'] = True\n",
    "    slide_dict['PathReportURL'] = \"TBD\"\n",
    "  \n",
    "    \n",
    "    slide_dict['TumorType'] = slideGroup\n",
    "    \n",
    "    \n",
    "    slide_name_noext = s['slide_name'].replace('.svs','')\n",
    "    slide_dict['slide_name_noext'] = slide_name_noext\n",
    "    slide_dict['slide_nouid'] = pt_id\n",
    "    \n",
    "    \n",
    "    foundFeatureDB = False\n",
    "    \n",
    "    FeatureColl = \"Features.V1.%s.%s\" % ( slideGroup, slide_name_noext)\n",
    "    \n",
    "    if FeatureColl in all_feature_colls:\n",
    "        foundFeatureDB = True\n",
    "    else:\n",
    "        FeatureColl = \"Features.V1.%s.%s\" % ( slideGroup, pt_id)\n",
    "        if FeatureColl in all_feature_colls:\n",
    "            foundFeatureDB = True\n",
    "\n",
    "    if foundFeatureDB:\n",
    "        \n",
    "        FeatObjs = feature_db[FeatureColl].count()\n",
    "        ##Feature database should be  Features.V1.[TumorType].SlideName (without the trailing crap)\n",
    "        slide_dict['FeatureDB_CollName'] =FeatureColl\n",
    "        if FeatObjs > 0:\n",
    "            slide_dict['HasAnnotations'] = True\n",
    "        else:\n",
    "            slide_dict['HasAnnotations'] = False\n",
    "\n",
    "        slide_dict['FeatObjs'] = FeatObjs\n",
    "\n",
    "        dsa_slide_db['PanCanDSA_Slide_Data'].insert_one(slide_dict)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'GBM', u'LGG', u'LUAD', u'SARC', u'SKCM']\n"
     ]
    }
   ],
   "source": [
    "coll_list = dsa_slide_db['PanCanDSA_Slide_Data'].distinct('slideGroup')\n",
    "dsa_slide_db['PanCanDSA_Slide_Data'].create_index('slideGroup')\n",
    "print coll_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-9e2bc2b5fc4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'Features'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mfeature_db\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mfeature_db\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/dgutman/Envs/ADRCFlask/local/lib/python2.7/site-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36mcreate_index\u001b[1;34m(self, keys, **kwargs)\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gen_index_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1380\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__create_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1381\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dgutman/Envs/ADRCFlask/local/lib/python2.7/site-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36m__create_index\u001b[1;34m(self, keys, index_options)\u001b[0m\n\u001b[0;32m   1288\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1289\u001b[0m                 self._command(\n\u001b[1;32m-> 1290\u001b[1;33m                     sock_info, cmd, read_preference=ReadPreference.PRIMARY)\n\u001b[0m\u001b[0;32m   1291\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOperationFailure\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1292\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOMMAND_NOT_FOUND_CODES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dgutman/Envs/ADRCFlask/local/lib/python2.7/site-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36m_command\u001b[1;34m(self, sock_info, command, slave_ok, read_preference, codec_options, check, allowable_errors, read_concern)\u001b[0m\n\u001b[0;32m    203\u001b[0m                                  \u001b[0mcheck\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                                  \u001b[0mallowable_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                                  read_concern=read_concern)\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dgutman/Envs/ADRCFlask/local/lib/python2.7/site-packages/pymongo/pool.pyc\u001b[0m in \u001b[0;36mcommand\u001b[1;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;31m# Catch socket.error, KeyboardInterrupt, etc. and close ourselves.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_connection_failure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_doc_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dgutman/Envs/ADRCFlask/local/lib/python2.7/site-packages/pymongo/pool.pyc\u001b[0m in \u001b[0;36m_raise_connection_failure\u001b[1;34m(self, error)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[0m_raise_connection_failure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#all_slides = dsa_slide_db['RawSlideData'].find()\n",
    "all_colls =  feature_db.collection_names()\n",
    "\n",
    "for a in all_colls:\n",
    "    if 'Features' in a:\n",
    "        feature_db[a].create_index('X')\n",
    "        feature_db[a].create_index('Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print dsa_slide_db['PanCanDSA_Slide_Data'].find_one({'slide_name': {\"$regex\": \"TCGA-3B-A9I1-01Z-00-DX1\"}  }\n",
    "                                             \n",
    "                                             )\n",
    "\n",
    "\n",
    "#{ <field>: { $regex: /pattern/, $options: '<options>' } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317837\n"
     ]
    }
   ],
   "source": [
    "dsa_slide_db['PanCanDSA_Slide_Data'].count()\n",
    "\n",
    "print feature_db['Features.V1.GBM.TCGA-02-0001-01Z-00-DX1'].count()\n",
    "#feature_db['Features.V1.LGG.TCGA-CS-4941-01Z-00-DX1.86D516B5-C648-4249-8C6A-7F9A6A56CB4F'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dsa_slide_db['DSA_Slide_Data'].distinct('pt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur= dsa_slide_db['DSA_Slide_Data'].find({'pt_id':'ADRC50-10'})\n",
    "for c in cur:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## Going to create a cleanup and /or reformatted collection for the DSA Viewer\n",
    "for s in dsa_slide_db['ADRC'].find():\n",
    "    keys_of_interest = ['width','height']\n",
    "    print s['slide_w_path']\n",
    "    print s.keys()\n",
    "    sys.exit()\n",
    "###\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
